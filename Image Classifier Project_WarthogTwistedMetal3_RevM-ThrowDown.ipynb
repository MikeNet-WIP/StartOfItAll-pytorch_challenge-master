{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU.....Left, Square, Square, Square, Left \n",
      "Time Stage: 0.111 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "from torch.nn import init\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "def random_seeding(seed_value, on_gpu):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    if on_gpu: torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "\n",
    "    \n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU.....Left, Square, Square, Square, Left ')\n",
    "    \n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_seeding(64,train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotda_training(train_losses, valid_losses):\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(valid_losses, label='Validation loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title('Loss progress')\n",
    "    ax.set_yscale('log')\n",
    "    plt.figure(figsize=(15,24))\n",
    "    plt.show()\n",
    "    plt.savefig('progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotda_learning(scheduler_steps):\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(scheduler_steps, label='LearningRate')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title('LearningRate progress')  \n",
    "    ax.set_yscale('log')\n",
    "    plt.figure(figsize=(15,24))\n",
    "    plt.show()\n",
    "    plt.savefig('LearningRate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "data_dir = 'C:/PyTorch/flower_data/'\n",
    "#data_dir = 'C:/PyTorch/flower_photos/'\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "valid_dir = os.path.join(data_dir, 'valid/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "\n",
    "dirs = {'train': train_dir, \n",
    "        'valid': valid_dir, \n",
    "        'test' : test_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  6552\n",
      "Num valid images:  832\n",
      "Num test images:  816\n",
      "Time Stage: 0.283 seconds\n"
     ]
    }
   ],
   "source": [
    "# load and transform data using ImageFolder\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(64),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=test_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num valid images: ', len(valid_data))\n",
    "print('Num test images: ', len(test_data))\n",
    "\n",
    "# define dataloader parameters\n",
    "batch_size = 130 #130 #30 #18\n",
    "num_workers= 8\n",
    "imagestoshow = 16#20#16#8\n",
    "n_epochs1 = 7\n",
    "n_epochs2 = 2\n",
    "lr1min = 1e-08\n",
    "lr1max = .006\n",
    "lr2min = 1e-08\n",
    "lr2max = 0.00008\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'pink primrose')\n"
     ]
    }
   ],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    \n",
    "class_names = train_data.classes\n",
    "\n",
    "sortedclasses = sorted(cat_to_name.items())\n",
    "print(sortedclasses[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "\n",
    "    img = img.transpose(1,2,0)\n",
    "    img = img * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    img = img.clip(0, 1)\n",
    "\n",
    "    plt.imshow(img)  # convert from Tensor image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "# display 20 images\n",
    "for idx in np.arange(imagestoshow):\n",
    "    ax = fig.add_subplot(4, imagestoshow/4, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(sortedclasses[labels[idx]])\n",
    "    \n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stage Start: 0.305 seconds\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): ClassifierNew(\n",
      "    (ap): AdaptiveAvgPool1d(output_size=512)\n",
      "    (mp): AdaptiveMaxPool1d(output_size=512)\n",
      "    (bn0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout0): Dropout(p=0.35)\n",
      "    (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout1): Dropout(p=0.35)\n",
      "    (fc2): Linear(in_features=500, out_features=102, bias=True)\n",
      "  )\n",
      ")\n",
      "Time Stage: 2.434 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# Load the pretrained model from pytorch\n",
    "model = models.resnet18(pretrained=True)\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#model = xception(True)\n",
    "# Freeze training for all \"features\" layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    \n",
    "#n_inputs = model.classifier.in_features\n",
    "n_inputs = model.fc.in_features\n",
    "#print(model.classifier.in_features) \n",
    "#print(model.classifier.out_features) \n",
    "int(round(n_inputs*0.8))\n",
    "\n",
    "      \n",
    "class ClassifierNew(nn.Module):\n",
    "    def __init__(self, inp = 512, h1=1024, out = 102, d=0.35):\n",
    "        super().__init__()\n",
    "        self.ap = nn.AdaptiveAvgPool1d(512)\n",
    "        self.mp = nn.AdaptiveMaxPool1d(512)\n",
    "        self.bn0 = nn.BatchNorm1d(512*2,eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.dropout0 = nn.Dropout(d)\n",
    "        self.fc1 = nn.Linear(512*2, 500)\n",
    "        self.bn1 = nn.BatchNorm1d(h1,eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.dropout1 = nn.Dropout(d)\n",
    "        self.fc2 = nn.Linear(500, out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ap = self.ap(x)\n",
    "        mp = self.mp(x)\n",
    "        x = torch.cat((ap,mp),dim=1)\n",
    "        x = x.view(-1, 512*2)\n",
    "        x = self.bn0(x)\n",
    "        x = self.dropout0(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)         \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "#model.classifier = classifier\n",
    "model.fc = ClassifierNew()\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "# if GPU is available, move the model to GPU\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0006, betas=(0.9, 0.999), eps=1e-08, \n",
    "#                       weight_decay=1e-05, amsgrad=True)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=lr1max, betas=(0.9, 0.999), eps=1e-08, \n",
    "                       weight_decay=1e-04, amsgrad=True)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr1max, betas=(0.9, 0.999), eps=1e-08, \n",
    "#                       weight_decay=1e-04, amsgrad=True)\n",
    "#optimizer = optim.Adam(model.classifier.parameters(), lr=lr1max, betas=(0.9, 0.999), eps=1e-08, \n",
    "#                       weight_decay=1e-04, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.10, patience=4, \n",
    "                                                 verbose=False, threshold=0.006, threshold_mode='rel', \n",
    "                                                 cooldown=0, min_lr=0, eps=1e-08)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Stage Start: 2.445 seconds\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'self' (while checking arguments for adaptive_avg_pool1d)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c8d305facbec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# calculate the batch loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-34db3c9f96d0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'self' (while checking arguments for adaptive_avg_pool1d)"
     ]
    }
   ],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "scheduler_steps = []\n",
    "\n",
    "for epoch in range(1, n_epochs1+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    start = time.time()\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model.forward(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    #    if batch_idx % 20 == 19:    # print training loss every specified number of mini-batches\n",
    "     #       print('\\t Epoch %d, Batch %d loss: %.16f' %\n",
    "      #            (epoch, batch_idx + 1, train_loss / 20))\n",
    "       #     print(f\"\\t \\tTime per batch: {(time.time() - start)/3:.3f} seconds\")\n",
    "        #    train_loss = 0.0\n",
    "        \n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model.forward(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    scheduler.step(valid_loss)\n",
    "    scheduler_steps.append(optimizer.param_groups[0]['lr'])\n",
    "    if optimizer.param_groups[0]['lr'] <= lr1min:\n",
    "        optimizer.param_groups[0]['lr']=lr1max\n",
    "        \n",
    "    #print('lr: {} '.format(optimizer.param_groups[0]['lr']))   \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tlr: {} '.format(\n",
    "        epoch, train_loss, valid_loss, optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        #torch.save(model.state_dict(), 'model_augmented.pt')\n",
    "        model.class_to_idx = train_data.class_to_idx\n",
    "        #model.cpu()\n",
    "        torch.save({'state_dict': model.state_dict(), \n",
    "                    'class_to_idx': model.class_to_idx}, \n",
    "                    'Project_WarthogRevMv2.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f\"Time per epoch: {(time.time() - start):.3f} seconds\")\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotda_training(train_losses,valid_losses)\n",
    "plotda_learning(scheduler_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(102))\n",
    "class_total = list(0. for i in range(102))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    #for i in range(20):\n",
    "    for i in range (len(target.data)): \n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "\n",
    "for i in range(102):\n",
    "   if class_total[i] > 0:\n",
    "       print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "           sortedclasses[i], 100 * class_correct[i] / class_total[i],\n",
    "           np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "   else:\n",
    "       print('Test Accuracy of %5s: N/A (no training examples)' % (i))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "   100. * np.sum(class_correct) / np.sum(class_total),\n",
    "   np.sum(class_correct), np.sum(class_total)))\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# move model inputs to cuda, if GPU available\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "if train_on_gpu:\n",
    "    images = images.cpu()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "for idx in np.arange(imagestoshow):\n",
    "    ax = fig.add_subplot(4, imagestoshow/4, idx+1, xticks=[], yticks=[])\n",
    "    #plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(\"{}\\n {}\".format(sortedclasses[preds[idx]], sortedclasses[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_checkpoint('Project_WarthogRevMv2.pth')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.00008, betas=(0.9, 0.999), eps=1e-08, \n",
    "#                       weight_decay=1e-04, amsgrad=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr2max, betas=(0.9, 0.999), eps=1e-08, \n",
    "                       weight_decay=1e-04, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.10, patience=4, \n",
    "                                                 verbose=False, threshold=0.0008, threshold_mode='rel', \n",
    "                                                 cooldown=0, min_lr=0, eps=1e-08)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# number of epochs to train the model\n",
    "\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "train_losses2 = []\n",
    "valid_losses2 = []\n",
    "\n",
    "for epoch in range(1, n_epochs2+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    start = time.time()\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model.forward(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    #    if batch_idx % 20 == 19:    # print training loss every specified number of mini-batches\n",
    "     #       print('\\t Epoch %d, Batch %d loss: %.16f' %\n",
    "      #            (epoch, batch_idx + 1, train_loss / 20))\n",
    "       #     print(f\"\\t \\tTime per batch: {(time.time() - start)/3:.3f} seconds\")\n",
    "        #    train_loss = 0.0\n",
    "        \n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model.forward(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    scheduler.step(valid_loss)\n",
    "    train_losses2.append(train_loss)\n",
    "    valid_losses2.append(valid_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    scheduler_steps.append(optimizer.param_groups[0]['lr'])\n",
    "    if optimizer.param_groups[0]['lr'] <= lr2min:\n",
    "        optimizer.param_groups[0]['lr']=lr2max\n",
    "    #print('lr: {} '.format(optimizer.param_groups[0]['lr']))   \n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tlr: {} '.format(\n",
    "        epoch, train_loss, valid_loss, optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        #torch.save(model.state_dict(), 'model_augmented.pt')\n",
    "        model.class_to_idx = train_data.class_to_idx\n",
    "        #model.cpu()\n",
    "        torch.save({'state_dict': model.state_dict(), \n",
    "                    'class_to_idx': model.class_to_idx}, \n",
    "                    'Project_WarthogRevMv2True.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f\"Time per epoch: {(time.time() - start):.3f} seconds\")\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotda_training(train_losses,valid_losses)\n",
    "plotda_training(train_losses2,valid_losses2)\n",
    "plotda_learning(scheduler_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(102))\n",
    "class_total = list(0. for i in range(102))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    #for i in range(20):\n",
    "    for i in range (len(target.data)): \n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "\n",
    "for i in range(102):\n",
    "   if class_total[i] > 0:\n",
    "       print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "           sortedclasses[i], 100 * class_correct[i] / class_total[i],\n",
    "           np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "   else:\n",
    "       print('Test Accuracy of %5s: N/A (no training examples)' % (i))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "   100. * np.sum(class_correct) / np.sum(class_total),\n",
    "   np.sum(class_correct), np.sum(class_total)))\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time Stage Start: {(time.time() - starttime):.3f} seconds\")\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# move model inputs to cuda, if GPU available\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "if train_on_gpu:\n",
    "    images = images.cpu()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "for idx in np.arange(imagestoshow):\n",
    "    ax = fig.add_subplot(4, imagestoshow/4, idx+1, xticks=[], yticks=[])\n",
    "    #plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(\"{}\\n {}\".format(sortedclasses[preds[idx]], sortedclasses[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pathtet = os.path.join(data_dir, 'test/98/image_07758.jpg')\n",
    "#imgtet = Image.open(image_pathtet)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    ''' \n",
    "    Scales, crops, and normalizes a PIL image for a PyTorch       \n",
    "    model, returns an Numpy array\n",
    "    '''\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Resize\n",
    "    if img.size[0] > img.size[1]:\n",
    "        img.thumbnail((5000, 256))\n",
    "    else:\n",
    "        img.thumbnail((256, 5000))\n",
    "\n",
    "    # Crop \n",
    "    left_margin = (img.width-224)/2\n",
    "    bottom_margin = (img.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    img = img.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    # Normalize\n",
    "    img = np.array(img)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406]) #Required mean\n",
    "    std = np.array([0.229, 0.224, 0.225]) #Required std\n",
    "    img = (img - mean)/std\n",
    "    \n",
    "    # Move color channels to first dimension as expected by PyTorch\n",
    "    #img = img.numpy().transpose((2, 0, 1))\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(image_pathtet)\n",
    "imshow(process_image(image_pathtet))\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "        # Process image\n",
    "    img = process_image(image_path)\n",
    "    \n",
    "    # Numpy -> Tensor\n",
    "    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "\n",
    "    # Add batch of size 1 to image\n",
    "    model_input = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Probs\n",
    "    probs = torch.exp(model.forward(model_input))\n",
    "    \n",
    "    # Top probs\n",
    "    top_probs, top_labs = probs.topk(topk)\n",
    "    top_probs = top_probs.detach().numpy().tolist()[0] \n",
    "    top_labs = top_labs.detach().numpy().tolist()[0]\n",
    "    \n",
    "    # Convert indices to classes\n",
    "    idx_to_class = {val: key for key, val in    \n",
    "                                      model.class_to_idx.items()}\n",
    "\n",
    "    top_labels = [idx_to_class[lab] for lab in top_labs]\n",
    "    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n",
    "\n",
    "    return top_probs, top_labels, top_flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, classes, flowers = predict(image_pathtet, model.cpu())\n",
    "print(probs)\n",
    "print(classes)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display an image along with the top 5 classes\n",
    "def plot_solution(image_path, model):\n",
    "    # Set up plot\n",
    "    plt.figure(figsize = (6,10))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "\n",
    "    # Set up title\n",
    "    flower_num = image_path.split('/')[4]\n",
    "    flowerClass = cat_to_name[flower_num]\n",
    "    #print(flower_num)\n",
    "    #print(flowerClass)\n",
    "    # Plot flower\n",
    "    img = process_image(image_path)\n",
    "    #imshow(img, ax, title = title_);\n",
    "    imshow(img, ax);\n",
    "    #ax.set_title(flowerClass, color=(\"green\"))\n",
    "\n",
    "\n",
    "    # Make prediction\n",
    "    probs, labs, flowers = predict(image_path, model) \n",
    "    \n",
    "    ax.set_title(\"{}-{}\".format(flower_num, flowerClass), \n",
    "                 color=(\"green\" if flower_num==labs[0] else \"red\"))\n",
    "\n",
    "    # Plot bar chart\n",
    "    plt.subplot(2,1,2)\n",
    "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solution(image_pathtet, model)\n",
    "probs, labs, flowers = predict(image_pathtet, model)\n",
    "print(probs)\n",
    "print(labs)\n",
    "print(flowers)\n",
    "print(f\"Time Stage: {(time.time() - starttime):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
